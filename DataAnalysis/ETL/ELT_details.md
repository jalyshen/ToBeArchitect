# ETL详解

原文：https://www.cnblogs.com/yjd_hycf_space/p/7772722.html



​        先来给**ETL**下个定义。

​        ETL是将业务系统的数据，经过**抽取、清洗转换之后，加载到数据仓库**的过程。目的，就是将企业中的**分散、零乱、标准不统一**的数据整合到一起，为企业的决策提供分析依据。

​        ETL是Bi项目的一个重要环节。通常情况下，在BI项目中ETL会花掉整个项目至少1/3的时间，ETL设计的好坏，直接关系到BI项目的成败。

​        ETL的实现有多种方法，常用的有三种。一种是借助ETL工具（如Oracle的OWB、SQL Server2000的DTS、SQL Server2005的SSIS服务、Informatic等）实现；一种是SQL方式实现；另一种是ETL工具和SQL相结合。前两种方法各有各的优缺点，借助工具可以快速的建立ETL工程，屏蔽复杂的编码任务，提高速度，降低难度；但是缺少灵活性。SQL的方法优点是灵活，提高ETL运行效率，但是编码复杂，对技术要求比较高。第三种是综合前两种的优点，可以极大地提高ETL的开发速度和效率。

## 一、数据的抽取（Extract）

​        数据的抽取，需要**在调研阶段**做大量的工作，首先要搞清楚数据是从几个业务系统中来，各个业务系统的数据服务器运行什么RDMS，是否存在手工数据，手工数据量有多大，是否存在非结构化的数据等等。当收集完这些信息之后，才可以进行数据抽取的设计。

### 1.1 对于与存放DW的数据库系统相同的数据源处理方法

​        这一类数据源在设计上比较容易。一般情况下，DBMS（SQL Server、Oracle）都会提供数据库链接功能，在DW数据库服务器和原业务系统之间建立直接的链接关系就可以写Select语句直接访问。

### 1.2 对于与DW数据库系统不同的数据源的处理方法

​        对于这类数据源，一帮情况下，也可以通过ODBC的方式建立数据库连接--如SQL Server与Oracle之间。如果不能建立数据库链接，可以有两种方式完成：一种是通过工具将源数据库导出成.txt或者.xls文件，然后通过将这些源系统文件导入到ODS中；另一种方法是通过程序接口来完成。

### 1.3 对于文件类型数据源（.txt, .xls, .cvs）

​        可以通过培训业务人员，利用数据库工具将需要的数据导入到指定的数据库，然后从指定的数据库中抽取；或者自研一个导入工具，完成导入工作。

### 1.4 增量更新的问题

​        对于数据量大的系统，**必须**考虑**增量**抽取。一般情况下，业务系统会记录业务发生的时间，可以用来做增量的标志。每次抽取之前，先判断ODS中记录数据的最大的时间，然后根据这个时间去业务系统抽取大于这个时间所有的记录。利用业务系统的时间戳，一般情况下，业务系统没有或者部分有时间戳。如果没有时间戳，可以根据别的递增关系的字段来选去增量数据。

## 二、数据的清洗转换（Cleaning、Transform）

​        一般情况下，数据仓库分为ODS、DW两部分。通常的做法是，**从业务系统到ODS做清洗，将脏数据和不完整的数据过滤掉，再从ODS到DW的过程中转换，进行一些业务规则的计算和聚合**。

### 2.1 数据清洗

​        数据清洗的任务，是过滤那些不符合要求的数据，将过滤的结果交给业务主管部分，确认是否过滤掉，还是由业务单位休整之后再进行抽取。

​        **不符合要求的数据，主要是不完整的数据、错误的数据、重复的数据三大类。**

* **不完整的数据**

  ​        这类数据主要是一些应该有的信息缺失，如供应商名称、分公司名称、客户所在地区信息、业务系统中主表与明细表不能匹配等等。对于这一类数据过滤出来，按缺失的内容分别写入不同的Excel文件，向客户提交，要求在规定的时间内补全。补全后再入库DW。

* **错误的数据**：

  ​        这类错误产生的原因，是业务系统不够健全，在接收输入后没有进行判断直接写入后台数据库的。比如数值数据输成了全角数字字符、字符串数据后面有一个回车操作、日期格式不正确、日期越界等。**这类数据要进行分类**。

  * 对于类似全角字符、数据前后有不可见字符的问题，只能通过写SQL的方式找出来，然后要求客户在业务系统修正之后再抽取；
  * 日期格式不正确，或者日期越界这一类错误，会导致ETL运行失败，这类错误需要去业务系统数据库用SQL的方式挑出来，交给业务主管部门要求限期修正，修正后再抽取；

* **重复的数据**：

  ​        对于这类数据，特别是维表中会出现这种情况--将重复数据记录的所有字段导出，让客户签字确认

​        数据清洗是一个反复的过程，不可能几天就完成，只有不断的发现问题、解决问题。对于是否过滤，是否修正，一般要求客户确认。对于过滤掉的数据，写入Excel文件或者将过滤数据写入数据表，在ETL开发的初期可以每天向业务单位发送过滤数据的邮件，催促他们尽快修正错误，同时也可以做为将来验证数据的依据。数据清洗需要注意的是不要将有用的数据过滤掉，对于每个过滤规则，要认证验证，并要求客户确认。

### 2.2 数据转换

​        数据转换的任务主要进行不一致的数据转换、数据粒度的转换，以及一些商务规则的计算。

* **不一致数据转换**：

  ​        这个过程是一个整合的过程，将不同业务系统的相同类型的数据统一，比如同一个供应商在结算系统的编码是xx0001，而在CRM系统中编码是YY0001，这样抽取过来之后统一转换成一个编码。

* **数据粒度的转换**：

  ​        业务系统一般存储非常明晰的数据，而数据仓库中数据是用来分析的，不需要非常明晰的数据。**一般情况下，需要将业务系统数据按照数据仓库粒度进行聚合**。

* **商务规则的计算**：

  ​        不同的企业有不同的业务规则、不同的数据指标，这些指标有时候不是简单的加减就能完成，需要在ETL中将这些数据指标计算好以后，存储在数据仓库中，以供分析使用。

## 三、ETL日志、警告发送

### 3.1 日志

​        **记录日志的目的是随时可以知道ETL运行情况，如果出错了，可以知道哪里出错。**ETL日志分为三类：

* **执行过程日志**：

  ​        这部分的日志是在ETL执行过程中每执行一步的记录，记录每次运行每一步的起始时间，影响了多少行数据，流水账的形式。

* **错误日志**：

  ​        当某个模块出错的时候写错误日志，记录每次出错的时间、出错的模块以及出错的信息等。

* **总体日志**：

  ​        只记录ETL开始时间、结束时间是否成功信息。如果使用ETL工具,ETL工具会自动产生一些日志，这一类日志也可以作为ETL日志的一部分。

### 3.2 警告发送

​        如果ETL出错了，不仅要形成ETL出错日志，而且要向系统管理员发送警告。发送警告的方式很多，一般常用的就是给系统管理员发送邮件，并附上出错的信息，方便管理员排查错误。



## 四、ETL特点

1. **数据同步**：

   它不是一次性倒完数据就拉到，它是经常性的活动，按照固定周期运行的，甚至现在还有人提出了实时ETL的概念。

2. **数据量**：

   一般都是巨大的，值得你将数据流动的过程拆分成E、T和L。

​        现在有很多成熟的工具提供ETL功能，且不说他们的好坏。从应用角度来说，ETL的过程其实不是非常复杂，这些工具给数据仓库工程带来和很大的便利性，特别是开发的便利和维护的便利。但另一方面，开发人员容易迷失在这些工具中。举个例子，VB是一种非常简单的语言并且也是非常易用的编程工具，上手特别快，但是真正VB的高手有多少？微软设计的产品通常有个原则是“将使用者当作傻瓜”，在这个原则下，微软的东西确实非常好用，但是对于开发者，如果你自己也将自己当作傻瓜，那就真的傻了。ETL工具也是一样，这些工具为我们提供图形化界面，让我们将主要的精力放在规则上，以期提高开发效率。从使用效果来说，确实使用这些工具能够非常快速地构建一个job来处理某个数据，不过从整体来看，并不见得他的整体效率会高多少。问题主要不是出在工具上，而是在设计、开发人员上。他们迷失在工具中，没有去探求ETL的本质。可以说这些工具应用了这么长时间，在这么多项目、环境中应用，它必然有它成功之处，它必定体现了ETL的本质。如果我们不透过表面这些工具的简单使用去看它背后蕴涵的思想，最终我们作出来的东西也就是一个个独立的job，将他们整合起来仍然有巨大的工作量。大家都知道“理论与实践相结合”，如果在一个领域有所超越，必须要在理论水平上达到一定的高度.