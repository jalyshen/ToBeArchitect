# 流式处理的一些概念（一）：时间域、窗口化

https://www.jianshu.com/p/2a8422f3a467

原文：

https://www.oreilly.com/radar/the-world-beyond-batch-streaming-101/



翻译更好的文章：

https://www.jianshu.com/p/e4c440d1beee



流式数据处理目前是大数据中的一个重要部分：

* 企业期望更及时的数据，切换到流式处理是实现低延迟的好办法
* 在现代商业中越来越普遍的大量无界数据集，使用为这种永无止境的数据量设计的系统更容易
* 当数据到达时，处理数据将工作负载随时间更均匀的分布，从而产生一致和可预测的资源消耗



### 关键信息描述

#### 什么是“流式”(Streaming)？

考虑到设计良好的流式系统与任何现有的批处理引擎一样能够产生正确的、一致和可重复的结果，将流式这个术语隔离到一个非常特定的含义：一种考虑到无限数据集而设计的数据处理引擎。（*PS：包含真正的流式传输和微批量实现*）

#### “流式系统”(Streaming System) 能做什么？

长期以来，流式系统一直被归类与能提供低延迟、不准确或推理的结果的有利市场，常常与更有能力的批处理系统结合以提供最终正确的结果。例如：Lambda架构，基本思想是，在Batch System旁运行Streaming System，两者执行基本相同的计算。流式系统提供低延迟、不准确的结果，一段时间后，批处理系统继续运行并提供正确的输出，需要构建两套体系。

#### Event-Time 和Processing-Time

在任何数据处理系统中，通常有两个关心的时间域（Time Domain）

* Event Time： 事件实际发生的时间
* Processing Time：在系统中处理的时间

虽然不是所有的场景都关心Event-Time，但很多情况都会关心。例如：描述用户随时间的行为、大多数计费应用程序以及许多类型的异常检测。



在理想的情况下，Event-Time 和Processing-Time是相等的，事件发生时立即处理。然而，现实情况并非如此，事件时间和处理时间之间的偏差不仅仅非零，而且常常受到底层输入源、执行引擎和硬件特性的影响，包括：

* 共享资源限制，例如：网络阻塞、网络分区或非专用环境中的共享CPU
* 软件原因，如分布式系统逻辑、征用等
* 数据本身特征，包括键值分布、吞吐量变化或无序变化

因此，对任何现实系统中的事件时间和处理时间的进展描述，通常都会得到一些类似于下图的理想情况和现实情况的偏差。

![](./images/concepts/EventTime-ProcessingTime.jpg)



黑虚线表示理想情况，斜率=1表示event time总是等于processing time；红线表示实际情况。在实际场景中系统总是会滞后一些，表现为processing time永远大于event time，但两者的差值其实一条变动的曲线，最开始时差距很大，在中段逐渐靠近理想情况，最后又开始偏离。曲线上同一个纵轴点对应的两个横坐标的差值即标识了现实与理想之间的skew——显然这种skew是因为数据处理管道的延时所引入的。

event time与processing time之间的差值不是固定的，这就意味着如果要使用event time，单靠processing time是不够的。令人遗憾地是，目前大多数streaming系统在设计的时候都只是考虑了processing time。如果要处理这种无穷多的数据，streaming系统必须要规定一种类似于时间窗口似的的概念。本质上它就是沿着时间维度把数据划分到不同的时间窗口中。虽然大部分系统就是这样做的， 但如果要实现基于event time的正确性，使用processing time来定义时间窗口显然是不行的。鉴于event time和processing time之间并没有一致性的关系，很有可能我们会把某些event time数据划分到错误的processing time窗口(比如因为延时)从而导致计算的不准确。后面需要详细讨论一下解决之道。

即使是根据event time进行时间窗口划分也不是所有问题都解决了。对于unbounded数据而言，无序性和skew的不确定性会带来一个完整性的问题：因为没有可控的event time/processing time映射关系，我们如何能够确定在时间窗口X中观测到的数据是完备的？真实场景中，我们无法提供完备性验证。主流的处理系统都依赖于完备性的概念，但当应用于无穷数据集时这些系统就有些捉襟见肘了。

与其把无限数据集打散到有限的batch中，不如设计一种工具能够应付真实场景下的这种不确定性。新数据必将到达，旧数据可能会被删除或更新，任何系统都应该独立地处理这些事情。在这些系统中完备性的概念只是一个辅助而非一个必要条件。

下面讨论一下常见的数据处理范型(data processing pattern)，既包括streaming引擎也包括batch引擎。micro-batch也被算作是streaming引擎。

### 通用数据处理模式(Common Data Processing Patterns)

现在我们开始研究在有界和无界数据处理中常用的核心使用模式类型。

#### 有界数据（Bounded Data）

处理有界数据相对简单，在下图中，左边的数据集杂乱无章，运行某个数据处理引擎后(通常是batch引擎，比如MapReduce)变成了右边的“更有序”的样子。怎么捣腾数据虽然玩法是无穷的，但万变不离其宗，这种处理方式是不变的，依然非常简单。有挑战的还是处理无穷数据集，包括batch处理无穷数据集和streaming处理无穷数据集。

![](./images/concepts/BoundedData.jpg)



#### 无界数据，微批(Unbounded Data - Batch)

虽然设计的时候并不是用于处理无穷数据集的，但batch引擎处理unbounded data可谓历史悠久，谁让batch是先发明出来的呢。具体的方法就是分而治之的思想，即以批处理的方式把无穷数据集划分成一组有限数据集进行处理。

##### 固定大小窗口(Fixed Windows)

最常用的方式就是不断执行batch引擎从而把输入数据划分成大小相等的窗口，如下图所示：

![](./images/concepts/FixedWindows.jpg)

然后独立地处理每个窗口中的数据。对于像日志这种类型的输入数据，日志被写入到不同的路径和文件中，因此路径和文件的名字就特别适合用于命名时间窗口。这样看来似乎事情变得非常简单了，只需要执行一个基于时间的路由策略就可以把所有数据按照event-time发送到不同的时间窗口中。在实际使用时，大多数的系统会遭遇完备性的问题：某些事件在写入到日之前被耽搁了(比如网络原因或磁盘IO)，或者事件虽然是全局收集的但在处理前被转移到一个公共的地方了，再或者事件是由移动设备发送过来的。这些情况中就需要一些手段来处理完备性，比如引入某种延时处理机制直到我们确信所有的时间都已经被收集了，或者只要那些晚到的数据到达，之前时间窗口中的数据就重新被处理一次。

##### 会话(Sessions)

当尝试使用批处理引擎将无界数据处理为更复杂的窗口策略（如用户会话）时，这种方式会更加崩溃。会话通常被定义为由一段不活动的间隙(a gap of inactivity)终止的活动时间段(Period of activity for a specific user)。当使用典型的批处理处理引擎计算会话时，通常以batch split结束会话，如下图中的红色标记所示。可以通过增加批量大小来减少split的数量，但是要以增加延迟为代价。另一个选项，是添加额外的逻辑来拼接之前运行的会话，但代价是更加复杂。无论哪种方式，使用传统的批处理引擎来计算会话都不太理想。

![](./images/concepts/SessionSplitData.jpg)



#### 无界数据，流式(Unbouned Data - Streaming)

与大多数基于批处理的无界数据处理方法的特殊性质相反，**流式系统针对无界数据构建**。对于许多真实世界的分布式输入源，不仅发现在处理无界数据，还要处理以下数据：

* 相对于事件时间高度无序，如果希望在事件时间的上下文中分析数据，需要在pipeline中进行某种基于时间的洗牌(shuffle)
* 对于变化的时间偏斜，意味着不能仅仅假设总在某个时间 $Y$ 的常量 $ε$ 内看到给定事件时间 $X$ 的大多数数据

在处理具有这些特性的数据时，有几种方式可以采用。通常将这些方法分为四类：

```powershell
Time-agnostic
Approximation
Windowing by processing time
Windowing by event time
```

##### 时间不可知论(Time-Agnostic)

如果本质上不关心时间——比如所有的逻辑都是数据驱动的——那么这类方法就非常适合了。其实这也没什么新鲜的，一个streaming引擎通常都是要支持的。本质上说，所有现存的streaming系统都天然支持这种与时间无关的使用场景。Batch系统也非常适合这种时间无关性的数据处理，只需简单地把无穷输入源划分成任意序列长度的有界数据集并分别独立处理即可。

下面举几个例子来说明一下：

##### 过滤(Filtering)

一个典型的例子就是过滤(filtering)，如下图所示：

![](./images/concepts/Data-Filtering.jpg)

假设处理的是Web流量日志，想要过滤出某个特定领域来的所有流量，那么只需查看每条日志的来源，如果不符合条件直接pass掉。显然这和时间是没有关系的，因此数据源是否是无序，无穷或是变动的skew就显得不重要了。

##### 内连接(Inner-Joins)

另一个时间无关性的例子就是内连接(inner-joins)。当连接两个无穷数据源时倘若只在乎连接的结果，则处理逻辑就不需要考虑时间的因素。一旦看到某股输入源中出现一个值，那么就把这个值缓存起来。当值出现在第二股输入源时，只需要发送合并的消息即可了，如下图所示：

![](./images/concepts/Inner-Joins.jpg)

如果切换到外连接将引入数据完备性的问题：一旦看到了join的一边，那么如何才能确定另一边也到达了呢？老实说，没法得知，因此就必须引入某种超时机制——而这必然会引入时间因素。时间因素本质上就是时间窗口的形式。

##### 近似算法(Approximation Algorithms)

第二大类方法就是近似算法，类似approximate Top-N、streaming K-means等。这些算法接收无穷数据源作为输入，而输出结果只能算是基本上满足预期。近似算法的好处在于开销很低并且天生就是用于处理无穷数据集的，而缺点在于算法通常是很复杂的，而且它们的近似特性限制了它们的应用。**值得注意的是，这些算法在设计上通常都引入了时间的元素。**算法在处理事件时，**时间因素通常都是基于processing time的**，这对于提供了某类可控错误边界的算法而言是极其重要的。近似算法本身也可以被视为是与时间无关性处理的另一个例子。

![](./images/concepts/Approximation.jpg)



#### 窗口化(Windowing)

剩下的两种无界数据处理方法都是窗口化的变体。**时间窗口本质上就是将数据源沿着时间线划分成有限的数据块**。下图表明不同的窗口范型：

![](./images/concepts/Window-Modules.jpg)



* **固定窗口**(Fixed Windows)：固定窗口将时间分割为具有固定大小的时间长度段。固定窗口被**均匀地**应用于整个数据集，这是对齐窗口的示例。在某些情况下，希望对数据的不同子集（例如：每个键）的窗口进行相位移，以便随着时间更均匀的分布窗口完成负载。
* **滑动窗口**(Sliding Windows)：这是一种固定窗口的推广模式，**滑动窗口由固定长度和固定周期定义**。如果周期小于长度，则窗口重叠。如果周期等于长度，则变为固定窗口。如果周期大于长度，那么就变为一个采样窗口，查看随时间变化的数据子集。与固定窗口一样，滑动窗口通常是对齐的，但是在某些场景中，可能作为性能优化而未对齐。
* **会话**(Sessions)：动态窗口的一个例子，**会话由一系列事件组成的，以一个超过 inactivity gap 的时间终止**。**会话通常用于分析随时间变化的用户行为，通过将一系列与时间相关的事件（例如：一次连续观看的视频序列）分组在一起。**会话的长度不能预先定义，取决于实际数据。会话是为对齐窗口的典型示例，因为会话在不同数据子集（例如：不同用户）之间从不相同。

对于processing time和event time而言，时间窗口都是适用的，当然还是有区别的。

首先来看基于processing time的时间窗口:

##### 处理时间窗口(Windowing by processing time)

![](./images/concepts/WindowingByProcessingTime.jpg)

根据 *processing time* 创建时间窗口时，系统会缓存输入数据到窗口中直至超过了某段时间。比方说对于5分钟的固定时间窗口，系统会缓存之前5分钟的所有数据并封装进一个窗口中，之后发送给下游系统用于处理。

处理时间窗口有以下几个很好的特性：

1. **实现非常简单**：不必担心在时间内对数据进行洗牌（shuffle）。只要在数据到达时缓冲它们，并在窗口关闭时将窗口数据发送到下游
2. **极易检验完备性**：由于系统完全知道是否已经看到窗口的所有收入，所以可以对给定的窗口是否完整做出完美的决策。这意味着在通过处理时间打开窗口时，不需要任何方式处理“延迟”数据
3. 如果你想根据观察结果推断关于源的信息，那么处理时间窗口正合适。许多监控场景都属于此类。想象一下：跟踪每秒发送给全局规模Web服务的请求数量；为了检测停机而计算这些请求的速率是完美利用处理时间窗口

不过这种基于 *processing time* 的窗口有一个非常大的缺陷：**必须要求数据按照 *event time* 顺序到达**，否则无法真实再现事件发生场景，但是按照event time顺序的输入数据几乎不存在。。。。举个简单的例子，假设手机上的一个app收集用户统计信息。当手机未连上网络时，这段时间内收集到的数据就无法上传。这就意味着数据可能比真实的发生时间晚几分钟、几个小时、几周甚至更长。在处理时间窗口时，期望从这样的数据集中获取任何有用的结论都是不可能的。另一个例子，假设有一个全球服务处理从各个大洲收集上来的数据。如果网络问题导致带宽受阻，那么此时必然造成数据的skew。如果对这种数据基于processing time做窗口，那么这种窗口就无法表达包含在它们之下数据的真实发生情况。相反地，它们表示的是事件到达时的情况，必然是新旧数据相互混合的。这两个例子其实都应该以event time进行时间窗口的划分——即所谓的基于event time的时间窗口

##### 事件时间窗口(Windowing by event time)

基于event time的时间窗口：**反映事件发生时间的时间窗口**。下图展示了一个基于event time的1小时固定时间窗口：

![](./images/concepts/WindowingByEventTime.jpg)

两条白线表明了两个特殊的数据：这两个数据点上的数据对应的processing time时间窗口与基于event time的时间窗口是错配的。因此如果使用基于processing time的时间窗口必然造成结果的不准确。由此可见，能够提供正确性是基于event time时间窗口的一大优势。

基于event time时间窗口的另一个优势在于它的大小可以动态变更，比如session，再不会有跨batch或跨窗口的情形发生，如下图所示：

![](./images/concepts/WindowingByEventTime-2.jpg)

当然，强大的语义都是有代价的，事件时间窗口也不例外。事件时间窗口有两个明显的缺点，因为窗口通常必须（相比处理时间）比窗口本身的实际长度更长：

* **需要额外缓冲区**：因为时间窗口的时间周期来拉长，需要缓存更多的数据。当然现在存储的成本不断下降，此缺陷便显得不是那么重要了
* **完整性**：因为无法明确得知某个窗口下的所有数据都已经到来，因此便无法确认何时才能开始处理这个窗口下的数据。在实践过程中，系统通常会给一个经验值来定义窗口的完备性，但如果从绝对正确性的角度来考虑，唯一的解决办法就是提供一种方式能够让窗口中的数据可以被重新处理从而不断修正计算结果