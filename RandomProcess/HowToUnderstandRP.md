# 如何从深刻地理解随机过程的含义

原文：https://www.zhihu.com/question/26694486/answer/349872296



## 第一部分：为什么要研究随机过程？

​        人类认识世界的历史，就是一认识和描绘各种运动的历史，从宏观的天体运动到分子的运动，到人心理的运动-我们通称为变化，就是一个东西随时间的改变。

​        人们最成功的描绘运动的模型是牛顿的天体运动，确定性是牛顿体系最大的特征。给定位置和速度，运动轨迹即确定。但是20世纪后的科学却失去了牛顿美丽的确定性光环。

​        因为当人们试图描绘一些真实世界，充满复杂而未知因素的运动时候，人们发现不确定因素（通常称为杂音）对事物的变化至关重要，而牛顿的方法几乎难以应用。而我们所**能够给出的最好的事物变化的东西，是一套叫概率论的东西。而与之相应的产生的一个全新的研究运动的方法-随机过程，对不确定性下的运动进行精细的数学描述**。

​        我们周边充满了各种各样的数据，所谓大数据时代，这些数据最基本的特点就是含有巨量的噪音， 而**随机过程就是从这些噪音里提取信息的武器。**

​        其实我们生活中也处处充满“噪音”。比如说我们每天发邮件，经常有一些人时回时不回。那些不回的人到底是忘了还是真的不想回，我们却不知道。一个书呆子统计学家会告诉你，你无法从一次的行为评判他，而要看他一贯的表现。

​        第一个随机过程方法的伟大胜利是爱因斯坦的布朗运动。一些小花粉在水里，受到水分子不停碰撞，而呈现随机的运动（花粉颗粒由于很小比较容易受到水分子热扰动的影响） 。 研究这些花粉的微小运动似乎有点天然呆，我们却从中找到了分子世界重要的信息。而花粉那无序与多变的轨道，也为我们提供了随机运动的范式（随机游走）。

![Brownian_movement](./images/how2UnderstandRP/Brownian_movement.jpg)

​                                                    计算机生成的十个粒子的布朗运动轨迹

​        如果给随机过程打个比方，它就像是一个充满交叉小径的花园。你站在现在的点上，看未来的变化，未来有千万种变化的方式， 每一种可能又不断分叉变化出其它可能。

## 第二部分：描述随机过程的武器

​         随机过程怎么研究？几样神器是不可缺少的。

### 1. 概率空间

​         面对不确定的未来，无非有两件事情需要关心：

* 一个是有哪些**可以实现的可能**：定义了一个事件空间（态空间）
* 一个是**每种可能的大小**：定义了一个数--概率。

​         关键这信息从哪儿来？如何知道要发生什么？又如何知道有多大可能发生？

​         概率论的思维基点其实是：日光下并无新事。

​         人们**对未来的预测来源于对过往的经验积累，而沟通过去经验与未来预测的工具就是概率。所谓一件事情发生可能性大小，就是一件事在历史中发生的频率**。

​         当然很多情况下概率也可以通过已知理论用演绎法推得，但是最根本的，还是由经验确定的概率。

​        **概率**，中学数学都学过，它是一个时间出现的频率，但它的含义其实很深很深。因为一个事件出现的频率来自于历史的总结，而**概率却用于对未来的预测**。因此，**概率包含的一个基本假设就是未来和过去的一致性**。一旦一些一个过程是一个随时间剧烈变化的过程，概率几乎不能应用。所以，这里只能说概率是一种近似，它对于研究那些比较简单的物理过程，如投掷硬币，才完全有效。

​         所以，所谓概率空间，只能是一种近似，它是人类现有知识的总和（综合？），用它描述已知的未知，但是却从来无法描述未知的未知（就是所谓的黑天鹅事件），因为真正的未来，永远无法只有已知的可能性。在大多数时候，还是日光下并无新事。因此，概率论的威力依然不可小觑。

​         有关概率空间的思维，可以立刻灭掉一些看似烧脑而实际脑残的题目：

​         假设你在进行一个游戏节目。现给三扇门供你选择：一扇门后面是一辆轿车，另两扇门后面什么都没有。你的目的当然是要想得到比较值钱的轿车，但你却并不能看到门后面的真实情况。主持人先让你作第一次选择。在你选择了一扇门后， 知道其余两扇门后面是什么的主持人，打开了另一扇门给你看，而且，当然，那里什么都没有。现在主持人告诉你，你还有一次选择的机会。那么，请你考虑一下，你是坚持第一次的选择不变，还是改变第一次的选择，更有可能得到轿车？

​         回答这个问题的关键即事件空间，在主持人打开门之前，事件空间即车的位置有三种可能，你有1/3 的可能拿到车。当主持人选择打开门的时候， 它实际上帮你做了一个选择，那就是告你某个车库没有车，这时候事件空间发生了变化，因为你的已知变了。如果说以前的事件空间是或者你选择的车库有车（1/3）， 或者另外两个车库中的某一个有车(各1/3)。现在的情况呢？被打开的车库有车的概率变为0， 因此你选择的车库没车的情况下车的位置已经变成确定的了，概率为2/3。而原来你车库有车的选项却不受到这一事件的影响（依然1/3概率）， 所以你当然要选择换车库。

​         这个例子第一个说明的道理是**概率是主观的，来自于你头脑中的信息**。

​         回过头看， 主持人的举动增加了你对两个车库的信息， 而车是不变的，所以你要根据新的信息调整概率空间。

> 此实例是好的思维方法的力量的典范，如果你没有这个事件空间的角度， 恐怕要做无数的试验了。



​         **条件概率**：现实生活中，一般都以条件概率的形式出现。即给定一定的已知条件，信息会得到什么样的概率。对这一大类问题，可以引出整个**贝叶斯分析理论**。

### 2. 随机变量

​         投掷筛子，得到6个结果，每种结果有1/6 的可能。把**态空间**的种种可能性都用数字表达出来，用一套用轻度装逼的数学语言描述， 就是随机变量。 这个东西包含所有输出的可能性以及相应的概率，这些**可能性（态空间）和概率的对应关系我们称之为分布函数**。如果态空间是连续的，我们就得到连续的分布函数形式。

<img src="./images/how2UnderstandRP/Gaussian_distribution_2d.jpg" alt="Gaussian_distribution_2d" style="zoom:67%;" />

​                                                                            一个二维高斯分布

#### 2.1 分布函数

​         随机变量已经包含了两个随机过程研究的核心武器：态空间和分布函数。分布函数是提取随机过程内有用信息的第一手段。**分布函数，是在大量数据中提取信息的入口**。

​         **随机变量的实现**：随机变量可以看作一个实验，在实验之前，结果是不确定的，所拥有的是一团可能性。当做完实验，却得到一个唯一的结果，知识预先不知道。

​         **期望**：对一个随机变量，*已知其分布函数*，可以定义一个期望。这个东西由每个结果的取值和它的可能性共同决定，表达未来结果的加权平均值。

​         实际中，可以用实验的方法确定这个数字，就是所谓蒙特卡洛方法。不停的投骰子，然后做个统计，所得到的结果的平均就是期望。（**平均值和期望的区别**：前者来自已有的数据的平均；后者是对根据已有的平均对未来的预测）。

​         关于期望，包含着一种投资世界里的基本思维方式，就是对收益的幅值和风险（概率）一起考虑。经常有一些时候一些出现机会极少而收益特别大的可能性决定了期望，如果你的心脏足够强大，就应该充分考虑这些高风险高收益的可能。

​         **相关性**：对于两个随机变量，可以定义一个相关性Convariance，描述一个随机变量随另一个而变化的趋势。这个函数特别有用，它是现实生活中常说两个事物相关性的**精确表达**。
$$
\sigma(x,y) = E[(x - E[x])(y - E[y])]
$$
理解这个算式特别简单，这个量就是 $x$ 和 $y$ 波动乘积的期望：

* 当两个变量是“此消彼长”时，则为负
* “共生共荣”时，则为正
* 若两个过程不相关，则为0

​         **方差**：上述关系，当$x = y$ 时，便得到了“方差”。方差，就是自己和自己的关联函数，当随机变量比较接近正态分布时，它可以描绘波动性的大小。

​         对于 $N$ 个随机变量，任意两个随机变量可以得到一个Convariance，而这样一组Convariance构成大名鼎鼎的Convariance Matrix：
$$
\sum = \begin{bmatrix} 
    E[(x_1 - \mu_1)(x_1 - \mu_1)] & E[(x_1 - \mu_1)(x_2 - \mu_2)] & \cdots & E[(x_1 - \mu_1)(x_n - \mu_n)] \\
    E[(x_2 - \mu_2)(x_1 - \mu_1)] & E[(x_2 - \mu_2)(x_2 - \mu_2)] & \cdots & E[(x_2 - \mu_2)(x_n - \mu_n)] \\
    \vdots & \vdots & \ddots & \vdots \\
    E[(x_n - \mu_n)(x_1 - \mu_1)] & E[(x_n - \mu_n)(x_2 - \mu_2)] & \cdots & E[(x_n - \mu_n)(x_n - \mu_n)] \\
\end{bmatrix}
$$


#### 2.2 测量分布函数的武器-蒙特卡洛方法

​         搞定一个分布函数，笨方法也是最有效的方法就是蒙特卡洛方法。例如，一般地说，骰子有6个面，每个面出现的概率有 $\frac{1}{6}$ ，但是万一骰子被动过手脚呢？所以最好的方法还是所谓蒙特卡洛抽样：不停的玩，直到认为可以**稳定**地得到每个面可能性出现的频率。所谓笨办法，确实是最常用的，尤其是随着高速计算机的普及，一些重大的工程，涉及太多复杂不好确定的因素时，就让计算机模拟，涉及一些列的蒙特卡洛抽样来求得一些结果。

#### 2.3 抽样

​         在计算机里研究牵扯随机变量的过程最基本的方法就是抽样。**抽样，就是一直分布函数取得一个随机的结果的过程**。

​        要在计算机里模拟一个随机过程都是通过抽样来实现的。抽样的成功与否，决定这些计算机模拟（simulation ）能在多少程度逼近真实。计算机的抽样都是基于最简单的随机数生成器产生的，产生的概率均等的均匀分布（Uniform Distribution）。但是这些“随机数”实际上是早已设定好的，因此更准确的被称作“伪随机数”。而对于更加复杂的分布函数的抽样，则有层出不穷的算法解决它，比如大名鼎鼎的Markov Chain Monte Carlo (MCMC) 方法。

## 第三方部分：什么是随机过程？

​        **确定性过程**，研究一个量随时间确定的变化，而**随机过程**，描述的是一个量随时间可能的变化。在这个过程中，每一个时刻变化的方向都是不确定的，或者说随机过程就是由一系列随机变量组成，每一个时刻系统的状态都有一个随机变量表述，而整个过程则构成态空间的一个轨迹（随机过程的实现）。